# üìä Sistema FAVISA - An√°lisis de Contribuyentes Chimbote

**Universidad Nacional del Santa | Arquitectura de Software Empresarial | Grupo B | 2026**

Demostraci√≥n acad√©mica de integraci√≥n **SQL Server + Apache Spark + Python** usando **Docker**.

---

### Flujo de ejecuci√≥n:

1. **SQL Server** arranca y espera conexiones
2. **Python** espera a que SQL Server est√© listo (healthcheck)
3. **Python** ejecuta `init.sql` ‚Üí crea FAVISA_DB con todas las tablas
4. **Python** lee el CSV y lo carga via `pyodbc` (tabla staging)
5. **Python** limpia datos sucios y migra a tabla `CONTRIBUYENTE`
6. **PySpark** se conecta a SQL Server via JDBC y realiza 6 an√°lisis
7. Los resultados se guardan en `RESULTADO_SPARK` y se muestran en consola
8. **Streamlit** lanza el dashboard web en el puerto 8501

---

## üìÅ Estructura del Proyecto

```
proyecto/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml    # Orquestaci√≥n de contenedores
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile            # Imagen Python personalizada
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îî‚îÄ‚îÄ init.sql              # Script BD completo (adaptado para Docker)
‚îú‚îÄ‚îÄ python/
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Orquestador principal
‚îÇ   ‚îú‚îÄ‚îÄ spark_job.py          # An√°lisis con Apache Spark
‚îÇ   ‚îú‚îÄ‚îÄ db_connection.py      # M√≥dulo de conexi√≥n SQL Server
‚îÇ   ‚îú‚îÄ‚îÄ dashboard.py          # Dashboard Streamlit
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt      # Dependencias Python
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ DataOZ_ChimboteNuevoCampo_03.csv   # Datos de contribuyentes
```

---

## ‚úÖ Requisitos Previos

Solo necesitas **Docker Desktop** instalado:

| Sistema | Link                                                     |
| ------- | -------------------------------------------------------- |
| Windows | https://docs.docker.com/desktop/install/windows-install/ |
| Mac     | https://docs.docker.com/desktop/install/mac-install/     |
| Linux   | https://docs.docker.com/desktop/install/linux-install/   |

Verificar instalaci√≥n:

```bash
docker --version
docker compose version
```

**Recursos recomendados para Docker Desktop:**

- RAM: m√≠nimo 6 GB asignados a Docker (8 GB recomendado)
- CPU: 2 cores m√≠nimo
- Disco: 10 GB libres

---

## üöÄ Ejecuci√≥n Paso a Paso

### 1. Clonar / Descomprimir el proyecto

```bash
# Si tienes git:
git clone <repositorio>

# O simplemente descomprimir el ZIP y entrar al directorio
cd proyecto
```

### 2. Ejecutar el sistema

```bash
# Desde la carpeta /docker (donde est√° el docker-compose.yml):
cd docker

# Construir im√°genes y levantar todos los contenedores:
docker compose up --build
```

> ‚è±Ô∏è **Primera vez**: puede tardar 5-10 minutos descargando im√°genes.
> Las siguientes ejecuciones tardan ~2 minutos.

### 3. Observar los logs

Ver√°s en consola algo as√≠:

```
favisa_sqlserver  | SQL Server is now ready for client connections.
favisa_python     | [PASO 1] Verificando conexi√≥n a SQL Server... ‚úÖ
favisa_python     | [PASO 2] Ejecutando script SQL...
favisa_python     | [PASO 3] Cargando CSV... 50,100 filas OK
favisa_python     | [PASO 4] Poblando cat√°logos...
favisa_python     | [PASO 5] Migrando datos...
favisa_python     | [PASO 6] Ejecutando an√°lisis Spark...
favisa_python     |   AN√ÅLISIS A: SALUD FISCAL DEL ECOSISTEMA
favisa_python     |   AN√ÅLISIS B: DISTRIBUCI√ìN GEOGR√ÅFICA
...
favisa_python     | Dashboard disponible en: http://localhost:8501
```

### 4. Acceder a las interfaces

| Interfaz                | URL                   | Descripci√≥n                         |
| ----------------------- | --------------------- | ----------------------------------- |
| **Dashboard principal** | http://localhost:8501 | Streamlit con gr√°ficos y resultados |
| **Spark Master UI**     | http://localhost:8080 | Estado del cluster Spark            |
| **Spark Worker UI**     | http://localhost:8081 | Tareas en ejecuci√≥n                 |

---

## üîÑ Re-ejecuci√≥n

Para ejecutar nuevamente sin reconstruir:

```bash
docker compose down
docker compose up
```

Para reconstruir la imagen Python (si cambias requirements.txt o Dockerfile):

```bash
docker compose up --build
```

Para ver solo los logs de un servicio:

```bash
docker compose logs python-app
docker compose logs sqlserver
docker compose logs spark-master
```

---

## üóÑÔ∏è Conectarse a SQL Server desde SSMS / DBeaver

Si quieres explorar la base desde una herramienta externa:

| Campo         | Valor            |
| ------------- | ---------------- |
| Servidor      | `localhost,1433` |
| Autenticaci√≥n | SQL Server       |
| Usuario       | `SA`             |
| Contrase√±a    | `FavisaDB2024!`  |
| Base de datos | `FAVISA_DB`      |

---

## üìä An√°lisis Spark Incluidos

| An√°lisis             | Descripci√≥n                                    | Relevancia FAVISA       |
| -------------------- | ---------------------------------------------- | ----------------------- |
| **A. Salud Fiscal**  | Estado tributario, deuda total/promedio/m√°xima | Riesgo de proveedores   |
| **B. Geograf√≠a**     | Top 15 distritos por concentraci√≥n             | Expansi√≥n CHIC/Eventos  |
| **C. Estructura**    | Tama√±o y tipo de empresa                       | Perfil de competidores  |
| **D. Sectores CIIU** | Top 20 + an√°lisis sectores 52xx, 15xx, 70xx    | Competencia directa     |
| **E. Demograf√≠a**    | Sexo, edad, rangos etarios                     | Segmentaci√≥n de mercado |
| **F. Calidad**       | Datos nulos, valores sucios normalizados       | Diagn√≥stico de datos    |

---

## üîß Troubleshooting

### "python-app se desconecta antes de que SQL Server est√© listo"

Normal en la primera ejecuci√≥n. El sistema tiene reintentos autom√°ticos
(cada 5 segundos, hasta 2 minutos). SQL Server tarda ~45-60s en arrancar.

### "Error JDBC: driver not found"

El JAR JDBC se descarga durante el build del Dockerfile. Si falla la descarga
(sin internet), puedes descargarlo manualmente:

```
https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/12.4.2.jre11/mssql-jdbc-12.4.2.jre11.jar
```

Y colocarlo en: `/opt/spark-jars/` dentro del contenedor.

### "Puerto 1433 ya en uso"

Tienes SQL Server local corriendo. Cambia el port mapping en docker-compose.yml:

```yaml
ports:
  - "1434:1433" # cambia el primer n√∫mero
```

### Ver qu√© hay en la BD sin SSMS:

```bash
docker exec -it favisa_sqlserver /opt/mssql-tools18/bin/sqlcmd \
  -S localhost -U SA -P 'FavisaDB2024!' \
  -Q "SELECT COUNT(*) FROM FAVISA_DB.dbo.CONTRIBUYENTE" -No -C
```

---

## üõë Detener el sistema

```bash
# Detener contenedores (mantiene datos):
docker compose down

# Detener Y borrar todos los datos (limpieza total):
docker compose down -v
```

---

## üìù Notas de Adaptaci√≥n del Script SQL

El script `init.sql` es el script original del equipo con estas adaptaciones m√≠nimas:

1. **Se removi√≥ `BULK INSERT`** ‚Üí La carga del CSV la hace Python (m√°s portable)
2. **Se agregaron valores al cat√°logo** de estados y condiciones que aparecen en el CSV real
3. **Se cre√≥ tabla `RESULTADO_SPARK`** para persistir los an√°lisis (no exist√≠a en original)
4. **Sin cambios en**: tablas, vistas, relaciones, √≠ndices, constraints de la estructura original

---

_Proyecto acad√©mico - Universidad Nacional del Santa - 2026_
